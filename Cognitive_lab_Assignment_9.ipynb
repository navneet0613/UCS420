{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzsOmd6Ea+IgBUNIFnjsyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneet0613/UCS420/blob/main/Cognitive_lab_Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submitted by: Navneet kaur(102497009)"
      ],
      "metadata": {
        "id": "s724MplH5wUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
        "technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuation.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribution (excluding stopwords)."
      ],
      "metadata": {
        "id": "ve4KOc8Tf820"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "#Convert to lowercase and remove punctuation\n",
        "text = \"\"\"Books have always been my favorite escape from reality. They let me travel to different worlds, meet fascinating characters, and experience new perspectives. Whether it's a mystery novel or a historical biography, books never fail to keep me engaged. Reading not only entertains me but also broadens my thinking and improves my language skills. I particularly enjoy reading before bed as it helps me relax. Nothing beats the feeling of getting lost in a good story.\"\"\"\n",
        "\n",
        "text_lower = text.lower()\n",
        "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "#Tokenize into words and sentences\n",
        "word_tokens = word_tokenize(text_clean)\n",
        "sentence_tokens = sent_tokenize(text_clean)\n",
        "\n",
        "# Step 3: Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in word_tokens if word not in stop_words]\n",
        "\n",
        "# Step 4: Display word frequency distribution (excluding stopwords)\n",
        "freq_dist = FreqDist(filtered_words)\n",
        "\n",
        "# Display results\n",
        "print(\"Tokenized Sentences:\")\n",
        "print(sentence_tokens)\n",
        "print(\"\\nTokenized Words (excluding stopwords):\")\n",
        "print(filtered_words)\n",
        "print(\"\\nWord Frequency Distribution:\")\n",
        "for word, freq in freq_dist.items():\n",
        "    print(f\"{word}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jADS2vPM4Q3V",
        "outputId": "f50f1913-1717-4541-d2f6-52bc8eb80efd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentences:\n",
            "['books have always been my favorite escape from reality they let me travel to different worlds meet fascinating characters and experience new perspectives whether its a mystery novel or a historical biography books never fail to keep me engaged reading not only entertains me but also broadens my thinking and improves my language skills i particularly enjoy reading before bed as it helps me relax nothing beats the feeling of getting lost in a good story']\n",
            "\n",
            "Tokenized Words (excluding stopwords):\n",
            "['books', 'always', 'favorite', 'escape', 'reality', 'let', 'travel', 'different', 'worlds', 'meet', 'fascinating', 'characters', 'experience', 'new', 'perspectives', 'whether', 'mystery', 'novel', 'historical', 'biography', 'books', 'never', 'fail', 'keep', 'engaged', 'reading', 'entertains', 'also', 'broadens', 'thinking', 'improves', 'language', 'skills', 'particularly', 'enjoy', 'reading', 'bed', 'helps', 'relax', 'nothing', 'beats', 'feeling', 'getting', 'lost', 'good', 'story']\n",
            "\n",
            "Word Frequency Distribution:\n",
            "books: 2\n",
            "always: 1\n",
            "favorite: 1\n",
            "escape: 1\n",
            "reality: 1\n",
            "let: 1\n",
            "travel: 1\n",
            "different: 1\n",
            "worlds: 1\n",
            "meet: 1\n",
            "fascinating: 1\n",
            "characters: 1\n",
            "experience: 1\n",
            "new: 1\n",
            "perspectives: 1\n",
            "whether: 1\n",
            "mystery: 1\n",
            "novel: 1\n",
            "historical: 1\n",
            "biography: 1\n",
            "never: 1\n",
            "fail: 1\n",
            "keep: 1\n",
            "engaged: 1\n",
            "reading: 2\n",
            "entertains: 1\n",
            "also: 1\n",
            "broadens: 1\n",
            "thinking: 1\n",
            "improves: 1\n",
            "language: 1\n",
            "skills: 1\n",
            "particularly: 1\n",
            "enjoy: 1\n",
            "bed: 1\n",
            "helps: 1\n",
            "relax: 1\n",
            "nothing: 1\n",
            "beats: 1\n",
            "feeling: 1\n",
            "getting: 1\n",
            "lost: 1\n",
            "good: 1\n",
            "story: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Stemming and Lemmatization\n",
        "1. Take the tokenized words from Question 1 (after stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply Lemmatization using NLTK's WordNetLemmatizer.\n",
        "4. Compare and display results of both techniques."
      ],
      "metadata": {
        "id": "7qC0ofJ75vON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # For lemmatizer support\n",
        "\n",
        "print(filtered_words) #filtered words from Q1\n",
        "\n",
        "# Initialize stemmers and lemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Prepare to store results\n",
        "results = []\n",
        "\n",
        "# Apply each technique to every word\n",
        "for word in filtered_words:\n",
        "    stem_porter = porter.stem(word)\n",
        "    stem_lancaster = lancaster.stem(word)\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    results.append((word, stem_porter, stem_lancaster, lemma))\n",
        "\n",
        "# Display results in a table format\n",
        "print(f\"{'Original':<15} {'PorterStemmer':<20} {'LancasterStemmer':<20} {'Lemmatized':<15}\")\n",
        "print(\"-\"*70)\n",
        "for orig, porter_s, lanc_s, lemma_w in results:\n",
        "    print(f\"{orig:<15} {porter_s:<20} {lanc_s:<20} {lemma_w:<15}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIMUzHeU6RuX",
        "outputId": "07cd1a7e-66e2-4dd2-e991-bb31ad9d19d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['books', 'always', 'favorite', 'escape', 'reality', 'let', 'travel', 'different', 'worlds', 'meet', 'fascinating', 'characters', 'experience', 'new', 'perspectives', 'whether', 'mystery', 'novel', 'historical', 'biography', 'books', 'never', 'fail', 'keep', 'engaged', 'reading', 'entertains', 'also', 'broadens', 'thinking', 'improves', 'language', 'skills', 'particularly', 'enjoy', 'reading', 'bed', 'helps', 'relax', 'nothing', 'beats', 'feeling', 'getting', 'lost', 'good', 'story']\n",
            "Original        PorterStemmer        LancasterStemmer     Lemmatized     \n",
            "----------------------------------------------------------------------\n",
            "books           book                 book                 book           \n",
            "always          alway                alway                always         \n",
            "favorite        favorit              favorit              favorite       \n",
            "escape          escap                escap                escape         \n",
            "reality         realiti              real                 reality        \n",
            "let             let                  let                  let            \n",
            "travel          travel               travel               travel         \n",
            "different       differ               diff                 different      \n",
            "worlds          world                world                world          \n",
            "meet            meet                 meet                 meet           \n",
            "fascinating     fascin               fascin               fascinating    \n",
            "characters      charact              charact              character      \n",
            "experience      experi               expery               experience     \n",
            "new             new                  new                  new            \n",
            "perspectives    perspect             perspect             perspective    \n",
            "whether         whether              wheth                whether        \n",
            "mystery         mysteri              mystery              mystery        \n",
            "novel           novel                novel                novel          \n",
            "historical      histor               hist                 historical     \n",
            "biography       biographi            biograph             biography      \n",
            "books           book                 book                 book           \n",
            "never           never                nev                  never          \n",
            "fail            fail                 fail                 fail           \n",
            "keep            keep                 keep                 keep           \n",
            "engaged         engag                eng                  engaged        \n",
            "reading         read                 read                 reading        \n",
            "entertains      entertain            entertain            entertains     \n",
            "also            also                 also                 also           \n",
            "broadens        broaden              broad                broadens       \n",
            "thinking        think                think                thinking       \n",
            "improves        improv               improv               improves       \n",
            "language        languag              langu                language       \n",
            "skills          skill                skil                 skill          \n",
            "particularly    particularli         particul             particularly   \n",
            "enjoy           enjoy                enjoy                enjoy          \n",
            "reading         read                 read                 reading        \n",
            "bed             bed                  bed                  bed            \n",
            "helps           help                 help                 help           \n",
            "relax           relax                relax                relax          \n",
            "nothing         noth                 noth                 nothing        \n",
            "beats           beat                 beat                 beat           \n",
            "feeling         feel                 feel                 feeling        \n",
            "getting         get                  get                  getting        \n",
            "lost            lost                 lost                 lost           \n",
            "good            good                 good                 good           \n",
            "story           stori                story                story          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Regular Expressions and Text spliting\n",
        "1. Take their original text from Question 1.\n",
        "2. Use regular expressions to:\n",
        "\n",
        "a. Extract all words with more than 5 letters.\n",
        "\n",
        "b. Extract all numbers (if any exist in their text).\n",
        "\n",
        "c. Extract all capitalized words.\n",
        "3. Use text spliting techniques to:\n",
        "\n",
        "a. Split the text into words containing only alphabets (removing digits and special\n",
        "characters).\n",
        "\n",
        "b. Extract words starting with a vowel."
      ],
      "metadata": {
        "id": "Tg-hOwTF95QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "\n",
        "import re\n",
        "\n",
        "# Q2 part a:\n",
        "a_words = re.findall(r'\\b\\w{6,}\\b', text)\n",
        "print(\"Words with more than 5 letters:\\n\",a_words)\n",
        "\n",
        "# Q2 part b:\n",
        "numbers = re.findall(r'\\b\\d+\\b', text)\n",
        "print(\"\\nNumbers in text:\")\n",
        "print(numbers if numbers else \"No numbers found\")\n",
        "\n",
        "# Q2 part c:\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text)\n",
        "print(\"\\nCapitalized words:\")\n",
        "print(capitalized_words)\n",
        "\n",
        "# Q3 part a:\n",
        "alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
        "print(\"\\nWords with only alphabets:\")\n",
        "print(alpha_words)\n",
        "\n",
        "# Q3 part b:\n",
        "vowel_words = [word for word in alpha_words if re.match(r'^[aeiouAEIOU]', word)]\n",
        "print(\"\\nWords starting with a vowel:\")\n",
        "print(vowel_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyVUGUdj95A9",
        "outputId": "7888ffd5-d1ad-438a-d1a5-70681847fff0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books have always been my favorite escape from reality. They let me travel to different worlds, meet fascinating characters, and experience new perspectives. Whether it's a mystery novel or a historical biography, books never fail to keep me engaged. Reading not only entertains me but also broadens my thinking and improves my language skills. I particularly enjoy reading before bed as it helps me relax. Nothing beats the feeling of getting lost in a good story.\n",
            "Words with more than 5 letters:\n",
            " ['always', 'favorite', 'escape', 'reality', 'travel', 'different', 'worlds', 'fascinating', 'characters', 'experience', 'perspectives', 'Whether', 'mystery', 'historical', 'biography', 'engaged', 'Reading', 'entertains', 'broadens', 'thinking', 'improves', 'language', 'skills', 'particularly', 'reading', 'before', 'Nothing', 'feeling', 'getting']\n",
            "\n",
            "Numbers in text:\n",
            "No numbers found\n",
            "\n",
            "Capitalized words:\n",
            "['Books', 'They', 'Whether', 'Reading', 'I', 'Nothing']\n",
            "\n",
            "Words with only alphabets:\n",
            "['Books', 'have', 'always', 'been', 'my', 'favorite', 'escape', 'from', 'reality', 'They', 'let', 'me', 'travel', 'to', 'different', 'worlds', 'meet', 'fascinating', 'characters', 'and', 'experience', 'new', 'perspectives', 'Whether', 'it', 's', 'a', 'mystery', 'novel', 'or', 'a', 'historical', 'biography', 'books', 'never', 'fail', 'to', 'keep', 'me', 'engaged', 'Reading', 'not', 'only', 'entertains', 'me', 'but', 'also', 'broadens', 'my', 'thinking', 'and', 'improves', 'my', 'language', 'skills', 'I', 'particularly', 'enjoy', 'reading', 'before', 'bed', 'as', 'it', 'helps', 'me', 'relax', 'Nothing', 'beats', 'the', 'feeling', 'of', 'getting', 'lost', 'in', 'a', 'good', 'story']\n",
            "\n",
            "Words starting with a vowel:\n",
            "['always', 'escape', 'and', 'experience', 'it', 'a', 'or', 'a', 'engaged', 'only', 'entertains', 'also', 'and', 'improves', 'I', 'enjoy', 'as', 'it', 'of', 'in', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Custom Tokenization & Regex-based Text Cleaning\n",
        "\n",
        "Take original text from Question 1.\n",
        "Write a custom tokenization function that:\n",
        "a. Removes punctuation and special symbols, but keeps contractions (e.g., \"isn't\" should not be split into \"is\" and \"n't\").\n",
        "\n",
        "b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains a single token).\n",
        "\n",
        "c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\" should remain as is). 3. Use Regex Substitutions (re.sub) to:\n",
        "\n",
        "a. Replace email addresses with '' placeholder.\n",
        "\n",
        "b. Replace URLs with '' placeholder.\n",
        "\n",
        "c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with '' placeholder"
      ],
      "metadata": {
        "id": "nymUbUFatXZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "import re\n",
        "\n",
        "# 2.\n",
        "def custom_tokenizer(text):\n",
        "    pattern = r\"\"\"\n",
        "        \\b\\d+\\.\\d+\\b              # decimal numbers\n",
        "        |\\b\\d+\\b                  # integers\n",
        "        |\\b\\w+(?:[-']\\w+)*\\b      # words with contractions or hyphens\n",
        "    \"\"\"\n",
        "    tokens = re.findall(pattern, text, re.VERBOSE)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# 3.\n",
        "def clean_text(text):\n",
        "    text1 = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w{2,4}\\b', '', text)  #replace email address\n",
        "    text1 = re.sub(r'https?://[^\\s]+', '', text) #Replace URLs\n",
        "    text1 = re.sub(r'\\+?\\d{1,3}[-\\s]?\\d{10}|\\d{3}[-]\\d{3}[-]\\d{4}', '', text)  #Replace phone numbers\n",
        "\n",
        "    return text1\n",
        "\n",
        "\n",
        "\n",
        "cleaned_text = clean_text(text)\n",
        "\n",
        "tokens = custom_tokenizer(cleaned_text)\n",
        "\n",
        "print(\"Cleaned Text:\\n\", cleaned_text)\n",
        "print(\"\\nCustom Tokens:\\n\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGrrFtyetd-R",
        "outputId": "81bba5ec-3f21-4b05-dac7-5fd6a705a084"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books have always been my favorite escape from reality. They let me travel to different worlds, meet fascinating characters, and experience new perspectives. Whether it's a mystery novel or a historical biography, books never fail to keep me engaged. Reading not only entertains me but also broadens my thinking and improves my language skills. I particularly enjoy reading before bed as it helps me relax. Nothing beats the feeling of getting lost in a good story.\n",
            "Cleaned Text:\n",
            " Books have always been my favorite escape from reality. They let me travel to different worlds, meet fascinating characters, and experience new perspectives. Whether it's a mystery novel or a historical biography, books never fail to keep me engaged. Reading not only entertains me but also broadens my thinking and improves my language skills. I particularly enjoy reading before bed as it helps me relax. Nothing beats the feeling of getting lost in a good story.\n",
            "\n",
            "Custom Tokens:\n",
            " ['Books', 'have', 'always', 'been', 'my', 'favorite', 'escape', 'from', 'reality', 'They', 'let', 'me', 'travel', 'to', 'different', 'worlds', 'meet', 'fascinating', 'characters', 'and', 'experience', 'new', 'perspectives', 'Whether', \"it's\", 'a', 'mystery', 'novel', 'or', 'a', 'historical', 'biography', 'books', 'never', 'fail', 'to', 'keep', 'me', 'engaged', 'Reading', 'not', 'only', 'entertains', 'me', 'but', 'also', 'broadens', 'my', 'thinking', 'and', 'improves', 'my', 'language', 'skills', 'I', 'particularly', 'enjoy', 'reading', 'before', 'bed', 'as', 'it', 'helps', 'me', 'relax', 'Nothing', 'beats', 'the', 'feeling', 'of', 'getting', 'lost', 'in', 'a', 'good', 'story']\n"
          ]
        }
      ]
    }
  ]
}